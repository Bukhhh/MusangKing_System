{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸˆ MusangKing FIXED Training v4\n",
                "## No Scaling (Compatible with app.py)\n",
                "\n",
                "**Problem Found:** Training used StandardScaler but app.py sends raw features.\n",
                "\n",
                "**Fix:** Train without scaling so it works directly with app.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install scikit-learn imbalanced-learn xgboost -q\n",
                "from google.colab import files\n",
                "print(\"ðŸ“¤ Upload features.csv\")\n",
                "uploaded = files.upload()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.metrics import classification_report, accuracy_score\n",
                "from imblearn.over_sampling import SMOTE\n",
                "import xgboost as xgb\n",
                "import joblib\n",
                "import os\n",
                "\n",
                "df = pd.read_csv('features.csv')\n",
                "print(f\"Loaded {len(df)} samples\")\n",
                "print(df['Variety'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# BALANCE by undersampling\n",
                "min_samples = df['Variety'].value_counts().min()\n",
                "target = int(min_samples * 1.5)\n",
                "\n",
                "balanced = []\n",
                "for var in df['Variety'].unique():\n",
                "    v_df = df[df['Variety'] == var]\n",
                "    if len(v_df) > target:\n",
                "        v_df = v_df.sample(n=target, random_state=42)\n",
                "    balanced.append(v_df)\n",
                "\n",
                "df_bal = pd.concat(balanced, ignore_index=True)\n",
                "print(\"Balanced:\")\n",
                "print(df_bal['Variety'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"TRAINING VARIETY MODEL (NO SCALING)\")\n",
                "\n",
                "FEATURES = ['Compactness', 'Smoothness', 'Aspect_Ratio', 'Rectangularity', 'Mean_Red']\n",
                "\n",
                "X = df_bal[FEATURES]  # NO SCALING!\n",
                "y = df_bal['Variety']\n",
                "\n",
                "variety_encoder = LabelEncoder()\n",
                "y_enc = variety_encoder.fit_transform(y)\n",
                "print(f\"Classes: {variety_encoder.classes_}\")\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=42, stratify=y_enc)\n",
                "\n",
                "smote = SMOTE(random_state=42, k_neighbors=3)\n",
                "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
                "print(f\"After SMOTE: {pd.Series(y_train_sm).value_counts().to_dict()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple Random Forest with class weights (most robust without scaling)\n",
                "variety_model = RandomForestClassifier(\n",
                "    n_estimators=300,\n",
                "    max_depth=12,\n",
                "    min_samples_split=4,\n",
                "    class_weight='balanced',\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "variety_model.fit(X_train_sm, y_train_sm)\n",
                "\n",
                "y_pred = variety_model.predict(X_test)\n",
                "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred)*100:.2f}%\")\n",
                "print(classification_report(y_test, y_pred, target_names=variety_encoder.classes_))\n",
                "\n",
                "# Check prediction distribution\n",
                "print(\"\\nPrediction Distribution:\")\n",
                "print(pd.Series(variety_encoder.inverse_transform(y_pred)).value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test with sample features (raw, no scaling)\n",
                "test_feats = pd.DataFrame([\n",
                "    [139, 0.005, 1.0, 0.7, 198],\n",
                "    [130, 0.015, 1.0, 0.7, 120],\n",
                "    [150, 0.020, 1.2, 0.8, 180]\n",
                "], columns=FEATURES)\n",
                "\n",
                "for i in range(len(test_feats)):\n",
                "    X_t = test_feats.iloc[[i]]\n",
                "    pred = variety_model.predict(X_t)[0]\n",
                "    proba = variety_model.predict_proba(X_t)[0]\n",
                "    name = variety_encoder.inverse_transform([pred])[0]\n",
                "    print(f\"Test {i+1}: {name} | {dict(zip(variety_encoder.classes_, [f'{p*100:.1f}%' for p in proba]))}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ripeness\n",
                "print(\"TRAINING RIPENESS MODEL\")\n",
                "\n",
                "df_bal['Ripeness'] = df_bal.apply(lambda r: 'defective' if r['Compactness'] > 150 else 'mature', axis=1)\n",
                "\n",
                "X_r = df_bal[['Mean_Hue', 'Compactness', 'Smoothness']]\n",
                "y_r = df_bal['Ripeness']\n",
                "\n",
                "ripeness_encoder = LabelEncoder()\n",
                "y_r_enc = ripeness_encoder.fit_transform(y_r)\n",
                "\n",
                "X_tr, X_te, y_tr, y_te = train_test_split(X_r, y_r_enc, test_size=0.2, random_state=42)\n",
                "\n",
                "ripeness_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
                "ripeness_model.fit(X_tr, y_tr)\n",
                "\n",
                "print(f\"Ripeness Accuracy: {accuracy_score(y_te, ripeness_model.predict(X_te))*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "OUTPUT = \"TRAINING_MODEL_V4\"\n",
                "os.makedirs(OUTPUT, exist_ok=True)\n",
                "\n",
                "joblib.dump(variety_model, f\"{OUTPUT}/variety_model.pkl\")\n",
                "joblib.dump(variety_encoder, f\"{OUTPUT}/variety_model_encoder.pkl\")\n",
                "joblib.dump(ripeness_model, f\"{OUTPUT}/ripeness_model.pkl\")\n",
                "joblib.dump(ripeness_encoder, f\"{OUTPUT}/ripeness_model_encoder.pkl\")\n",
                "\n",
                "print(\"âœ… Saved!\")\n",
                "!ls -la {OUTPUT}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!zip -r models_v4_noscale.zip TRAINING_MODEL_V4/\n",
                "\n",
                "from google.colab import files\n",
                "files.download('models_v4_noscale.zip')\n",
                "\n",
                "print(\"\\nðŸŽ‰ DONE! This version works with app.py (no scaling needed)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}